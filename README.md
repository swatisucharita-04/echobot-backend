Absolutely! Here's a **complete, ready-to-copy `README.md`** that you can paste directly into VS Code:

```markdown
# echobot-backend
Backend for EchoBot â€“ Conversational AI using STT, LLM, and TTS

# ğŸ™ï¸ EchoBot â€“ AI Voice Agent

**EchoBot** is a real-time AI-powered voice agent that listens to user speech, understands it using AI, and responds back using **Murf AI** voices.  
It combines **Speech-to-Text (STT)**, **AI reasoning**, and **Text-to-Speech (TTS)** to create a seamless conversation experience.

---

## âœ¨ Features
- ğŸ¤ **Voice Recording** â€“ Capture user audio directly in the browser.
- ğŸ“ **Speech-to-Text** â€“ Convert spoken audio into text using **AssemblyAI**.
- ğŸ¤– **AI Understanding** â€“ Process user queries with **Google Gemini AI**.
- ğŸ—£ **Text-to-Speech** â€“ Generate natural-sounding responses with **Murf AI**.
- ğŸŒ **Real-time Web Interface** â€“ Interactive UI with playback support.
- ğŸ”„ **End-to-End Flow** â€“ Fully integrated voice conversation cycle.

---

## ğŸ›  Technologies Used
### Frontend
- HTML5, CSS3, JavaScript
- Audio recording via MediaRecorder API (STT input)
- Fetch API for server communication

### Backend
- Python 3.x
- FastAPI (for API endpoints)
- Murf AI TTS API (Text-to-Speech)
- AssemblyAI STT API (Speech-to-Text)
- Google Gemini AI API (AI conversation logic)

---

## ğŸŒ Live Demo
Check out the live version of EchoBot here: [https://echobot-backend-6yr8.onrender.com/]

---

## ğŸ— Architecture

**Flow Diagram:**

```

\[User Voice Input] â†’ \[Frontend Recorder] â†’ \[Backend API]
â†“                     â†“
\[AssemblyAI STT] â†’ \[Google Gemini AI Processing] â†’ \[Murf AI TTS]
â†“                     â†“
\[Audio Response] â† \[Frontend Playback]

````

This represents the complete voice agent pipeline from capturing audio to generating responses.

---

## â–¶ï¸ How to Run Locally

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/echobot.git
cd echobot
````

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Set environment variables

Create a `.env` file in the project root and add:

```
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
MURF_API_KEY=your_murf_api_key
GEMINI_API_KEY=your_gemini_api_key
```

### 4ï¸âƒ£ Start the backend server

```bash
uvicorn app:app --reload
```

### 5ï¸âƒ£ One-Command Smoke Test

You can quickly test the full voice agent flow using:

```bash
python smoke_test.py
```

**smoke\_test.py** should:

* Record a short audio sample
* Process it through STT â†’ LLM â†’ TTS
* Play the generated audio

---

## ğŸ›  Troubleshooting

* **Latency issues**: Ensure your internet is stable; close other apps using the microphone.
* **Microphone permissions**: Check OS/browser settings to allow mic access.
* **Dependencies errors**: Run `pip install -r requirements.txt` and verify `.env` keys are correct.
* **Audio not playing**: Ensure `generated_audio/` folder exists and is writable.

---

## ğŸ“‚ Project Structure

```
echobot/
â”œâ”€â”€ __pycache__/                 # Python bytecode cache
â”œâ”€â”€ .vscode/                     # VSCode project settings
â”œâ”€â”€ models/                      # AI/ML model scripts or saved models
â”œâ”€â”€ node_modules/                # Node.js dependencies
â”œâ”€â”€ recordings/                  # Audio recordings
â”œâ”€â”€ services/                    # Modular service scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm.py                   # Large Language Model related functions
â”‚   â”œâ”€â”€ stt.py                   # Speech-to-Text services
â”‚   â””â”€â”€ tts.py                   # Text-to-Speech services
â”œâ”€â”€ static/                      # Frontend assets
â”‚   â”œâ”€â”€ generated_audio/         # Generated TTS audio files
â”‚   â”œâ”€â”€ JS_audio-processor.js
â”‚   â”œâ”€â”€ JS_audioPlayer.js
â”‚   â”œâ”€â”€ fallback.mp3             # Fallback audio
â”‚   â”œâ”€â”€ favicon.ico
â”‚   â”œâ”€â”€ JS_processor.js
â”‚   â”œâ”€â”€ JS_script.js
â”‚   â”œâ”€â”€ JS_Server.js
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ templates/                   # HTML templates
â”‚   â””â”€â”€ index.html               # Main UI
â”œâ”€â”€ uploads/                     # User-uploaded files
â”œâ”€â”€ venv/                        # Python virtual environment
â”œâ”€â”€ app.py                       # Main FastAPI app
â”œâ”€â”€ chat.py                      # Chat management
â”œâ”€â”€ config.py                    # App configuration
â”œâ”€â”€ models.py                    # ML/AI models
â”œâ”€â”€ murff_config.py              # Murf TTS API config
â”œâ”€â”€ server.py                    # Backend server script
â”œâ”€â”€ test_env.py                  # Environment testing
â”œâ”€â”€ test.py                      # Unit tests
â”œâ”€â”€ transcriber.py               # Audio transcription
â”œâ”€â”€ chat_memory.json             # Conversation history
â”œâ”€â”€ package.json                 # Node.js config
â”œâ”€â”€ package-lock.json            # Node.js dependency lock
â”œâ”€â”€ .env                         # Environment variables
â”œâ”€â”€ .gitignore                   # Git ignore file
â”œâ”€â”€ README.md                    # Project documentation
â””â”€â”€ requirements.txt             # Python dependencies
```

---

## ğŸ¤ Contribution

Contributions are welcome! Please fork the repo and submit a pull request.

---

## ğŸ“ License

MIT License

```
